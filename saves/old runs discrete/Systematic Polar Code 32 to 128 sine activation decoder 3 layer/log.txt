[INFO: train.py:  330]: training with the following args:
[INFO: train.py:  331]: ==================================================
[INFO: train.py:  333]: alphabet_size: 2
[INFO: train.py:  333]: batch_size: 256
[INFO: train.py:  333]: channel_prob: 0.1
[INFO: train.py:  333]: checkpoint_load_path: None
[INFO: train.py:  333]: clip: 1
[INFO: train.py:  333]: code_length: 128
[INFO: train.py:  333]: decoder_d_hidden: 16
[INFO: train.py:  333]: decoder_e_hidden: 8
[INFO: train.py:  333]: decoder_forward: 32
[INFO: train.py:  333]: decoder_lr: 0.01
[INFO: train.py:  333]: encoder_lr: 0.001
[INFO: train.py:  333]: eval_every: 500
[INFO: train.py:  333]: eval_size: 2048
[INFO: train.py:  333]: gamma: 0.7
[INFO: train.py:  333]: log_name: Systematic Polar Code 32 to 128 sine activation decoder 3 layer
[INFO: train.py:  333]: message_length: 32
[INFO: train.py:  333]: num_sample: 16
[INFO: train.py:  333]: save_model: True
[INFO: train.py:  333]: seed: 1
[INFO: train.py:  333]: steps: 100000
[INFO: train.py:  333]: train_encoder: False
[INFO: train.py:  334]: ==================================================
[INFO: train.py:  336]: Training on 25600000 datapoints with 100000 steps and batchsize 256
[INFO: train.py:  359]: The encoder has 0 trainable parameters.
[INFO: train.py:  360]: The decoder has 3524 trainable parameters.
[INFO: train.py:  201]: [train] Step: 1/100000 (0%)	Loss: 1.336110	 BER: 0.6165771484375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 2/100000 (0%)	Loss: 1.043111	 BER: 0.536376953125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 3/100000 (0%)	Loss: 0.941742	 BER: 0.4996337890625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 4/100000 (0%)	Loss: 0.889583	 BER: 0.5091552734375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 5/100000 (0%)	Loss: 0.849346	 BER: 0.49755859375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 6/100000 (0%)	Loss: 0.823832	 BER: 0.500244140625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 7/100000 (0%)	Loss: 0.801050	 BER: 0.4947509765625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 8/100000 (0%)	Loss: 0.782419	 BER: 0.4906005859375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 9/100000 (0%)	Loss: 0.767535	 BER: 0.4925537109375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 10/100000 (0%)	Loss: 0.755353	 BER: 0.50048828125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 11/100000 (0%)	Loss: 0.744832	 BER: 0.507080078125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 12/100000 (0%)	Loss: 0.736253	 BER: 0.501708984375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 13/100000 (0%)	Loss: 0.729037	 BER: 0.5048828125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 14/100000 (0%)	Loss: 0.723133	 BER: 0.4957275390625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 15/100000 (0%)	Loss: 0.718472	 BER: 0.4976806640625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 16/100000 (0%)	Loss: 0.714795	 BER: 0.4996337890625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 17/100000 (0%)	Loss: 0.711796	 BER: 0.497802734375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 18/100000 (0%)	Loss: 0.709352	 BER: 0.4984130859375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 19/100000 (0%)	Loss: 0.707273	 BER: 0.4984130859375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 20/100000 (0%)	Loss: 0.705770	 BER: 0.5072021484375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 21/100000 (0%)	Loss: 0.703767	 BER: 0.50048828125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 22/100000 (0%)	Loss: 0.702865	 BER: 0.5084228515625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 23/100000 (0%)	Loss: 0.701900	 BER: 0.5052490234375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 24/100000 (0%)	Loss: 0.700823	 BER: 0.5023193359375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 25/100000 (0%)	Loss: 0.699939	 BER: 0.495361328125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 26/100000 (0%)	Loss: 0.699314	 BER: 0.50439453125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 27/100000 (0%)	Loss: 0.698949	 BER: 0.5078125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 28/100000 (0%)	Loss: 0.698216	 BER: 0.497802734375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 29/100000 (0%)	Loss: 0.697834	 BER: 0.503173828125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 30/100000 (0%)	Loss: 0.697561	 BER: 0.5072021484375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 31/100000 (0%)	Loss: 0.697165	 BER: 0.5030517578125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 32/100000 (0%)	Loss: 0.696904	 BER: 0.503173828125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 33/100000 (0%)	Loss: 0.696590	 BER: 0.5009765625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 34/100000 (0%)	Loss: 0.696369	 BER: 0.500244140625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 35/100000 (0%)	Loss: 0.696095	 BER: 0.4957275390625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 36/100000 (0%)	Loss: 0.696271	 BER: 0.5069580078125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 37/100000 (0%)	Loss: 0.695991	 BER: 0.505615234375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 38/100000 (0%)	Loss: 0.695694	 BER: 0.4951171875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 39/100000 (0%)	Loss: 0.695954	 BER: 0.5067138671875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 40/100000 (0%)	Loss: 0.695211	 BER: 0.48583984375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 41/100000 (0%)	Loss: 0.695906	 BER: 0.5091552734375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 42/100000 (0%)	Loss: 0.695187	 BER: 0.4888916015625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 43/100000 (0%)	Loss: 0.695206	 BER: 0.49951171875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 44/100000 (0%)	Loss: 0.695012	 BER: 0.4837646484375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 45/100000 (0%)	Loss: 0.695071	 BER: 0.4949951171875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 46/100000 (0%)	Loss: 0.695493	 BER: 0.5025634765625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 47/100000 (0%)	Loss: 0.695232	 BER: 0.49951171875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 48/100000 (0%)	Loss: 0.695061	 BER: 0.5023193359375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 49/100000 (0%)	Loss: 0.694911	 BER: 0.5128173828125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 50/100000 (0%)	Loss: 0.694728	 BER: 0.4970703125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 51/100000 (0%)	Loss: 0.695204	 BER: 0.5052490234375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 52/100000 (0%)	Loss: 0.695027	 BER: 0.5057373046875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 53/100000 (0%)	Loss: 0.694666	 BER: 0.5093994140625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 54/100000 (0%)	Loss: 0.694741	 BER: 0.4981689453125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 55/100000 (0%)	Loss: 0.694548	 BER: 0.4921875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 56/100000 (0%)	Loss: 0.695204	 BER: 0.4990234375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 57/100000 (0%)	Loss: 0.695167	 BER: 0.50390625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 58/100000 (0%)	Loss: 0.694470	 BER: 0.4964599609375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 59/100000 (0%)	Loss: 0.694478	 BER: 0.4949951171875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 60/100000 (0%)	Loss: 0.695060	 BER: 0.5072021484375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 61/100000 (0%)	Loss: 0.694592	 BER: 0.500732421875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 62/100000 (0%)	Loss: 0.694515	 BER: 0.505859375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 63/100000 (0%)	Loss: 0.694363	 BER: 0.498291015625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 64/100000 (0%)	Loss: 0.695263	 BER: 0.510986328125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 65/100000 (0%)	Loss: 0.694622	 BER: 0.5035400390625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 66/100000 (0%)	Loss: 0.694315	 BER: 0.504150390625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 67/100000 (0%)	Loss: 0.694699	 BER: 0.5062255859375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 68/100000 (0%)	Loss: 0.694666	 BER: 0.5018310546875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 69/100000 (0%)	Loss: 0.694143	 BER: 0.4931640625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 70/100000 (0%)	Loss: 0.694373	 BER: 0.503173828125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 71/100000 (0%)	Loss: 0.694162	 BER: 0.496337890625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 72/100000 (0%)	Loss: 0.694319	 BER: 0.4998779296875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 73/100000 (0%)	Loss: 0.694293	 BER: 0.4959716796875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 74/100000 (0%)	Loss: 0.694760	 BER: 0.503173828125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 75/100000 (0%)	Loss: 0.694377	 BER: 0.5064697265625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 76/100000 (0%)	Loss: 0.694162	 BER: 0.49755859375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 77/100000 (0%)	Loss: 0.694882	 BER: 0.50634765625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 78/100000 (0%)	Loss: 0.693932	 BER: 0.4901123046875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 79/100000 (0%)	Loss: 0.694197	 BER: 0.4964599609375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 80/100000 (0%)	Loss: 0.693996	 BER: 0.491455078125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 81/100000 (0%)	Loss: 0.694105	 BER: 0.5025634765625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 82/100000 (0%)	Loss: 0.694025	 BER: 0.4952392578125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 83/100000 (0%)	Loss: 0.693883	 BER: 0.4906005859375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 84/100000 (0%)	Loss: 0.694615	 BER: 0.499755859375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 85/100000 (0%)	Loss: 0.694148	 BER: 0.495361328125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 86/100000 (0%)	Loss: 0.694166	 BER: 0.5015869140625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 87/100000 (0%)	Loss: 0.694032	 BER: 0.4991455078125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 88/100000 (0%)	Loss: 0.694205	 BER: 0.5	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 89/100000 (0%)	Loss: 0.694094	 BER: 0.496337890625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 90/100000 (0%)	Loss: 0.694219	 BER: 0.500244140625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 91/100000 (0%)	Loss: 0.693963	 BER: 0.5029296875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 92/100000 (0%)	Loss: 0.693924	 BER: 0.4976806640625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 93/100000 (0%)	Loss: 0.694209	 BER: 0.5032958984375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 94/100000 (0%)	Loss: 0.694036	 BER: 0.4990234375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 95/100000 (0%)	Loss: 0.694118	 BER: 0.5078125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 96/100000 (0%)	Loss: 0.694100	 BER: 0.5052490234375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 97/100000 (0%)	Loss: 0.694273	 BER: 0.50634765625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 98/100000 (0%)	Loss: 0.693840	 BER: 0.496337890625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 99/100000 (0%)	Loss: 0.693891	 BER: 0.4981689453125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 100/100000 (0%)	Loss: 0.693950	 BER: 0.5003662109375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 101/100000 (0%)	Loss: 0.693824	 BER: 0.4951171875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 102/100000 (0%)	Loss: 0.694069	 BER: 0.5015869140625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 103/100000 (0%)	Loss: 0.693910	 BER: 0.498046875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 104/100000 (0%)	Loss: 0.693830	 BER: 0.499267578125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 105/100000 (0%)	Loss: 0.693820	 BER: 0.497314453125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 106/100000 (0%)	Loss: 0.693790	 BER: 0.4971923828125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 107/100000 (0%)	Loss: 0.693749	 BER: 0.491943359375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 108/100000 (0%)	Loss: 0.693807	 BER: 0.494873046875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 109/100000 (0%)	Loss: 0.694012	 BER: 0.5023193359375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 110/100000 (0%)	Loss: 0.693784	 BER: 0.4949951171875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 111/100000 (0%)	Loss: 0.693775	 BER: 0.4947509765625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 112/100000 (0%)	Loss: 0.693775	 BER: 0.4981689453125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 113/100000 (0%)	Loss: 0.693762	 BER: 0.4976806640625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 114/100000 (0%)	Loss: 0.694090	 BER: 0.508056640625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 115/100000 (0%)	Loss: 0.693818	 BER: 0.4976806640625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 116/100000 (0%)	Loss: 0.693699	 BER: 0.490966796875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 117/100000 (0%)	Loss: 0.693811	 BER: 0.5001220703125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 118/100000 (0%)	Loss: 0.693608	 BER: 0.4898681640625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 119/100000 (0%)	Loss: 0.693843	 BER: 0.502197265625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 120/100000 (0%)	Loss: 0.693761	 BER: 0.49853515625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 121/100000 (0%)	Loss: 0.693697	 BER: 0.4964599609375	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 122/100000 (0%)	Loss: 0.693681	 BER: 0.499267578125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 123/100000 (0%)	Loss: 0.693963	 BER: 0.5045166015625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 124/100000 (0%)	Loss: 0.693610	 BER: 0.4901123046875	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 125/100000 (0%)	Loss: 0.693615	 BER: 0.4967041015625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 126/100000 (0%)	Loss: 0.693678	 BER: 0.496337890625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 127/100000 (0%)	Loss: 0.693896	 BER: 0.5074462890625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 128/100000 (0%)	Loss: 0.693699	 BER: 0.4986572265625	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 129/100000 (0%)	Loss: 0.693929	 BER: 0.5020751953125	 BLER: 1.0
[INFO: train.py:  201]: [train] Step: 130/100000 (0%)	Loss: 0.693852	 BER: 0.4979248046875	 BLER: 1.0
